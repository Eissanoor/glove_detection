"""
Professional Glove Detection UI with Advanced Hand Tracking
Features real-time hand tracking with moving bounding boxes
"""

import io
from pathlib import Path
import tempfile
import time
import streamlit as st
from PIL import Image
import cv2
import numpy as np
import mediapipe as mp

from hand_tracker import ProfessionalHandTracker
from config import CONF_THRESHOLD_DEFAULT

st.set_page_config(page_title="Professional Glove Detector", page_icon="üß§", layout="centered")

st.title("üß§ Professional Glove vs No-Glove Detector")
st.caption("Advanced hand tracking with moving bounding boxes for real-time safety monitoring.")

with st.sidebar:
    st.header("‚öôÔ∏è Professional Settings")
    
    # Model selection
    model_mode = st.radio(
        "Detection Mode:",
        ["Professional Tracking", "Basic Classification"],
        help="Professional mode uses MediaPipe for hand tracking + glove classification. Basic mode uses only glove classification."
    )
    
    model_path = st.text_input("Model path", value="runs/detect/glove_model.h5")
    conf_thres = st.slider("Confidence Threshold", 0.0, 1.0, float(CONF_THRESHOLD_DEFAULT), 0.01)
    img_size = st.selectbox("Image Size", [224, 320, 416, 512, 640], index=4)
    
    # Professional tracking settings
    if model_mode == "Professional Tracking":
        st.subheader("üéØ Tracking Settings")
        smoothing_factor = st.slider("Smoothing Factor", 0.0, 1.0, 0.7, 0.1, 
                                   help="Higher values = smoother tracking, lower values = more responsive")
        max_hands = st.selectbox("Max Hands to Track", [1, 2, 3, 4, 5], index=1)
        
        st.subheader("üìä Professional Features")
        show_landmarks = st.checkbox("Show Hand Landmarks", value=False)
        show_confidence = st.checkbox("Show Confidence Scores", value=True)
        show_tracking_info = st.checkbox("Show Tracking Info", value=True)
    
    st.header("üé• Detection Mode")
    detection_mode = st.radio(
        "Choose detection mode:",
        ["Image Upload", "Video Upload", "Webcam"]
    )
    
    predict_button = st.button("üöÄ Run Professional Detection", type="primary")

# File uploader based on mode
if detection_mode == "Image Upload":
    uploaded = st.file_uploader("Upload an image", type=["jpg", "jpeg", "png", "bmp", "webp"])
    video_uploaded = None
elif detection_mode == "Video Upload":
    video_uploaded = st.file_uploader("Upload a video", type=["mp4", "avi", "mov", "mkv", "webm"])
    uploaded = None
else:  # Webcam mode
    uploaded = None
    video_uploaded = None

# Load model
@st.cache_resource
def load_professional_tracker(model_path, img_size):
    """Load professional hand tracker"""
    try:
        return ProfessionalHandTracker(model_path, img_size)
    except Exception as e:
        st.error(f"Could not load professional tracker: {e}")
        return None

@st.cache_resource
def load_basic_model(model_path):
    """Load basic classification model"""
    try:
        import tensorflow as tf
        from tensorflow import keras
        return keras.models.load_model(model_path)
    except Exception as e:
        st.error(f"Could not load basic model: {e}")
        return None

def process_image_professional(tracker, image, conf_thres):
    """Process image with professional tracking"""
    # Convert PIL to OpenCV format
    cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
    
    # Process with professional tracker
    processed_image, hands_data = tracker.process_frame(cv_image, conf_thres)
    
    # Convert back to RGB for display
    result_image_rgb = cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB)
    
    return result_image_rgb, hands_data

def process_image_basic(model, image, conf_thres, img_size):
    """Process image with basic classification"""
    # Convert PIL to OpenCV format
    cv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
    
    # Preprocess image
    processed_img = cv2.resize(cv_image, (img_size, img_size))
    processed_img = cv2.cvtColor(processed_img, cv2.COLOR_BGR2RGB)
    processed_img = processed_img.astype('float32') / 255.0
    processed_img = np.expand_dims(processed_img, axis=0)
    
    # Make prediction
    predictions = model.predict(processed_img, verbose=0)
    
    # Get results
    class_id = np.argmax(predictions[0])
    confidence = predictions[0][class_id]
    classes = ['No Glove', 'Glove']
    
    # Draw result
    if confidence > conf_thres:
        predicted_class = classes[class_id]
        # Draw basic bounding box
        height, width = cv_image.shape[:2]
        if predicted_class == "No Glove":
            box_size = min(width, height) // 5
            x1 = (width - box_size) // 2
            y1 = (height - box_size) // 2
            x2 = x1 + box_size
            y2 = y1 + box_size
            cv2.rectangle(cv_image, (x1, y1), (x2, y2), (0, 0, 255), 3)
        
        # Draw label
        label = f"{predicted_class}: {confidence:.3f}"
        color = (0, 0, 255) if predicted_class == "No Glove" else (0, 255, 0)
        cv2.putText(cv_image, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
    
    result_image_rgb = cv2.cvtColor(cv_image, cv2.COLOR_BGR2RGB)
    
    return result_image_rgb, [{'class': predicted_class if confidence > conf_thres else 'Unknown', 
                              'confidence': confidence, 'bbox': None}]

def process_video_professional(tracker, video_file, conf_thres):
    """Process video with professional tracking"""
    # Save uploaded video to temporary file
    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
        tmp_file.write(video_file.read())
        tmp_path = tmp_file.name
    
    cap = cv2.VideoCapture(tmp_path)
    processed_frames = []
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    
    frame_count = 0
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    tracking_stats = {'total_detections': 0, 'no_glove_detections': 0, 'glove_detections': 0}
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
            
        frame_count += 1
        progress = frame_count / total_frames
        progress_bar.progress(progress)
        status_text.text(f"Processing frame {frame_count}/{total_frames}")
        
        # Process with professional tracker
        processed_frame, hands_data = tracker.process_frame(frame, conf_thres)
        
        # Update statistics
        for hand in hands_data:
            tracking_stats['total_detections'] += 1
            if hand['class'] == 'no_glove':
                tracking_stats['no_glove_detections'] += 1
            else:
                tracking_stats['glove_detections'] += 1
        
        processed_frames.append(processed_frame)
    
    cap.release()
    Path(tmp_path).unlink()
    
    return processed_frames, fps, tracking_stats

# Main interface
if detection_mode == "Image Upload":
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üì∏ Input Image")
        if uploaded:
            image = Image.open(uploaded).convert("RGB")
            st.image(image, use_column_width=True)
        else:
            st.info("Upload an image to begin.")

    with col2:
        st.subheader("üéØ Detection Result")
        if predict_button and uploaded:
            if model_mode == "Professional Tracking":
                tracker = load_professional_tracker(model_path, img_size)
                if tracker is None:
                    st.stop()
                
                with st.spinner("Running professional hand tracking..."):
                    result_image, hands_data = process_image_professional(tracker, image, conf_thres)
                
                st.image(result_image, use_column_width=True)
                
                # Display detection info
                if hands_data:
                    st.success(f"üéØ Detected {len(hands_data)} hand(s)")
                    for i, hand in enumerate(hands_data):
                        if hand['class'] == 'no_glove':
                            st.error(f"‚ö†Ô∏è Hand {i+1}: {hand['class']} (conf: {hand['confidence']:.3f})")
                        else:
                            st.success(f"‚úÖ Hand {i+1}: {hand['class']} (conf: {hand['confidence']:.3f})")
                else:
                    st.info("No hands detected")
                    
            else:  # Basic mode
                model = load_basic_model(model_path)
                if model is None:
                    st.stop()
                
                with st.spinner("Running basic detection..."):
                    result_image, hands_data = process_image_basic(model, image, conf_thres, img_size)
                
                st.image(result_image, use_column_width=True)
                
                if hands_data[0]['confidence'] > conf_thres:
                    if hands_data[0]['class'] == 'No Glove':
                        st.error(f"‚ö†Ô∏è Detection: {hands_data[0]['class']} (conf: {hands_data[0]['confidence']:.3f})")
                    else:
                        st.success(f"‚úÖ Detection: {hands_data[0]['class']} (conf: {hands_data[0]['confidence']:.3f})")
                else:
                    st.warning(f"Low confidence detection: {hands_data[0]['confidence']:.3f}")

elif detection_mode == "Video Upload":
    if video_uploaded:
        st.subheader("üé¨ Video Processing")
        st.write(f"**Video file:** {video_uploaded.name}")
        
        if predict_button:
            if model_mode == "Professional Tracking":
                tracker = load_professional_tracker(model_path, img_size)
                if tracker is None:
                    st.stop()
                
                with st.spinner("Processing video with professional tracking..."):
                    processed_frames, fps, stats = process_video_professional(tracker, video_uploaded, conf_thres)
                
                st.success(f"‚úÖ Processed {len(processed_frames)} frames successfully!")
                
                # Display tracking statistics
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Total Detections", stats['total_detections'])
                with col2:
                    st.metric("No Glove Detections", stats['no_glove_detections'], 
                             delta=f"{stats['no_glove_detections']/max(stats['total_detections'],1)*100:.1f}%")
                with col3:
                    st.metric("Glove Detections", stats['glove_detections'],
                             delta=f"{stats['glove_detections']/max(stats['total_detections'],1)*100:.1f}%")
                
                # Create and display processed video
                if processed_frames:
                    output_path = "professional_processed_video.mp4"
                    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                    height, width = processed_frames[0].shape[:2]
                    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
                    
                    for frame in processed_frames:
                        # Convert RGB to BGR for video writing
                        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                        out.write(frame_bgr)
                    out.release()
                    
                    st.subheader("üé• Processed Video with Professional Tracking")
                    st.video(output_path)
                    
                    # Download button
                    with open(output_path, "rb") as file:
                        st.download_button(
                            label="üì• Download Professional Video",
                            data=file.read(),
                            file_name=f"professional_{video_uploaded.name}",
                            mime="video/mp4"
                        )
                    
                    Path(output_path).unlink()
            else:
                st.info("Basic video processing not implemented. Please use Professional Tracking mode.")
    else:
        st.info("Upload a video file to begin processing.")

elif detection_mode == "Webcam":
    st.subheader("üìπ Live Webcam Detection")
    st.info("Professional webcam detection requires running the command line tool.")
    
    if model_mode == "Professional Tracking":
        st.code("""
# Run professional webcam detection:
python src/hand_tracker.py --source 0 --weights runs/detect/glove_model.h5 --conf 0.5
        """)
    else:
        st.code("""
# Run basic webcam detection:
python src/infer_tf.py --source 0 --weights runs/detect/glove_model.h5 --conf 0.5 --show
        """)

# Professional features documentation
st.markdown("""
---

## üöÄ **Professional Features**

### **üéØ Advanced Hand Tracking:**
- **Real-time hand detection** using MediaPipe
- **Moving bounding boxes** that follow hand movement
- **Smooth tracking** with configurable smoothing factor
- **Multi-hand support** (track up to 5 hands simultaneously)

### **üìä Professional Visualization:**
- **Red square boxes** for no_glove detections
- **Green square boxes** for glove detections
- **Corner markers** for enhanced visibility
- **Confidence scores** and tracking information
- **Real-time statistics** for video processing

### **‚öôÔ∏è Technical Specifications:**
- **Hand Detection**: MediaPipe Hands (70% detection confidence)
- **Glove Classification**: Your trained TensorFlow model
- **Tracking Smoothing**: Configurable (0.0-1.0)
- **Input Resolution**: Configurable (224-640 pixels)
- **Output Format**: Professional video with tracking overlay

### **üéØ Use Cases:**
- **Safety Compliance Monitoring**: Real-time glove detection in industrial settings
- **Quality Control**: Automated safety equipment verification
- **Training Analysis**: Review safety compliance in recorded videos
- **Live Monitoring**: Continuous safety monitoring with alerts

### **üìà Performance Benefits:**
- **Accurate Hand Tracking**: Follows hand movement precisely
- **Reduced False Positives**: Better hand detection reduces misclassifications
- **Professional Output**: High-quality visualization for reports and analysis
- **Scalable**: Supports multiple hands and various video formats
""")

st.markdown("""
---

## üîß **Training vs Testing Requirements**

### **‚úÖ Current Implementation (Testing Time Only):**
- Uses existing trained model for glove classification
- Adds MediaPipe hand tracking (no training required)
- Combines both in real-time for professional tracking

### **üîÑ Optional Retraining (For Even Better Results):**
- Train advanced model with bounding box regression: `python src/train_advanced.py`
- This would enable even more precise hand localization
- Not required for current professional tracking functionality

### **üéØ Recommendation:**
Start with the current professional tracking implementation. It provides excellent results using your existing model combined with MediaPipe hand tracking. You can always retrain later for even better precision if needed.
""")
